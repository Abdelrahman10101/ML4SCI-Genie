{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install gdown\n! gdown --id 1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr -O filename\n! pip install h5p\n! pip install torch_geometric\n! pip install torch_sparse torch_scatter torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__.split('+')[0])\")+cpu.html","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:28:49.917335Z","iopub.execute_input":"2025-04-01T09:28:49.917647Z","iopub.status.idle":"2025-04-01T09:29:19.851338Z","shell.execute_reply.started":"2025-04-01T09:28:49.917584Z","shell.execute_reply":"2025-04-01T09:29:19.850237Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.17.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2025.1.31)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr\nFrom (redirected): https://drive.google.com/uc?id=1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr&confirm=t&uuid=5a0d3c53-1b08-44e8-ba59-cde7deb121da\nTo: /kaggle/working/filename\n100%|█████████████████████████████████████████| 701M/701M [00:06<00:00, 107MB/s]\n\u001b[31mERROR: Could not find a version that satisfies the requirement h5p (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for h5p\u001b[0m\u001b[31m\n\u001b[0mCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\nLooking in links: https://data.pyg.org/whl/torch-2.5.1+cpu.html\nCollecting torch_sparse\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcpu/torch_sparse-0.6.18%2Bpt25cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch_scatter\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcpu/torch_scatter-2.1.2%2Bpt25cpu-cp310-cp310-linux_x86_64.whl (543 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.0/544.0 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch_cluster\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcpu/torch_cluster-1.6.3%2Bpt25cpu-cp310-cp310-linux_x86_64.whl (785 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.3/785.3 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch_spline_conv\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt25cpu-cp310-cp310-linux_x86_64.whl (238 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch_sparse) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy->torch_sparse) (2024.2.0)\nInstalling collected packages: torch_spline_conv, torch_scatter, torch_sparse, torch_cluster\nSuccessfully installed torch_cluster-1.6.3+pt25cpu torch_scatter-2.1.2+pt25cpu torch_sparse-0.6.18+pt25cpu torch_spline_conv-1.2.2+pt25cpu\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import MessagePassing, global_mean_pool\nfrom sklearn.neighbors import radius_neighbors_graph\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import roc_auc_score\nimport gc\n\n# ======================\n# 1. Graph Construction\n# ======================\ndef multi_channel_image_to_graph(ecal, hcal, track, threshold=0.01):\n    \"\"\"Convert 3-channel jet image to graph\"\"\"\n    nodes = []\n    height, width = ecal.shape\n    \n    for i in range(height):\n        for j in range(width):\n            total_energy = ecal[i,j] + hcal[i,j] + track[i,j]\n            if total_energy > threshold:\n                nodes.append([\n                    i/float(height),   # Normalized x\n                    j/float(width),    # Normalized y\n                    ecal[i,j],         # ECAL\n                    hcal[i,j],         # HCAL\n                    track[i,j]         # Track\n                ])\n    \n    if len(nodes) == 0:  # Fallback for empty graphs\n        combined = ecal + hcal + track\n        max_idx = np.unravel_index(np.argmax(combined), combined.shape)\n        nodes.append([\n            max_idx[0]/float(height), max_idx[1]/float(width),\n            ecal[max_idx], hcal[max_idx], track[max_idx]\n        ])\n    \n    nodes = np.array(nodes, dtype=np.float32)\n    pos = nodes[:, :2]\n    \n    if len(nodes) > 1:\n        edges = radius_neighbors_graph(pos, radius=0.15, mode='connectivity')\n        edge_index = torch.tensor(edges.nonzero(), dtype=torch.long)\n    else:\n        edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n    \n    return Data(x=torch.tensor(nodes, dtype=torch.float),\n                edge_index=edge_index)\n\n# ======================\n# 2. Data Loading\n# ======================\ndef load_data(filename, num_jets=30000, threshold=0.01):\n    \"\"\"Load jet data from HDF5 and convert to graphs\"\"\"\n    graphs = []\n    with h5py.File(filename, 'r') as f:\n        X_jets = f['X_jets'][:num_jets]  # Load first `num_jets` jets\n        m0 = f['m0'][:num_jets]\n        pt = f['pt'][:num_jets]\n        y = f['y'][:num_jets]\n        \n        for i in tqdm(range(num_jets), desc=\"Creating graphs\"):\n            ecal = X_jets[i, 0, :, :]  # ECAL channel\n            hcal = X_jets[i, 1, :, :]  # HCAL channel\n            track = X_jets[i, 2, :, :]  # Track channel\n            \n            data = multi_channel_image_to_graph(ecal, hcal, track, threshold)\n            data.m0 = torch.tensor([m0[i]], dtype=torch.float)\n            data.pt = torch.tensor([pt[i]], dtype=torch.float)\n            data.y = torch.tensor([int(y[i])], dtype=torch.long)\n            graphs.append(data)\n    \n    return graphs\n\n# ======================\n# 3. Non-Local Block\n# ======================\nclass NonLocalBlock(nn.Module):\n    def __init__(self, in_channels, reduction=2):\n        super().__init__()\n        self.inter_channels = in_channels // reduction\n        \n        self.theta = nn.Linear(in_channels, self.inter_channels)\n        self.phi = nn.Linear(in_channels, self.inter_channels)\n        self.g = nn.Linear(in_channels, self.inter_channels)\n        self.out = nn.Linear(self.inter_channels, in_channels)\n    \n    def forward(self, x, batch):\n        N = x.size(0)\n        \n        theta = self.theta(x)  # [N, inter_channels]\n        phi = self.phi(x)      # [N, inter_channels]\n        g = self.g(x)          # [N, inter_channels]\n        \n        # Attention scores [N, N]\n        attention = torch.matmul(theta, phi.T) / np.sqrt(self.inter_channels)\n        attention = F.softmax(attention, dim=-1)\n        \n        # Aggregation\n        out = torch.matmul(attention, g)  # [N, inter_channels]\n        out = self.out(out)  # [N, in_channels]\n        \n        return out + x  # Residual connection\n\n# ======================\n# 4. GNN Models\n# ======================\nclass EdgeConv(MessagePassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr='mean')\n        self.mlp = nn.Sequential(\n            nn.Linear(2*in_channels, out_channels),\n            nn.ReLU(),\n            nn.BatchNorm1d(out_channels),\n            nn.Linear(out_channels, out_channels)\n        )\n    \n    def forward(self, x, edge_index):\n        return self.propagate(edge_index, x=x)\n    \n    def message(self, x_i, x_j):\n        return self.mlp(torch.cat([x_i, x_j-x_i], dim=1))\n\nclass JetGNN(nn.Module):\n    def __init__(self, node_features=5, hidden_dim=64):\n        super().__init__()\n        self.conv1 = EdgeConv(node_features, hidden_dim)\n        self.conv2 = EdgeConv(hidden_dim, hidden_dim)\n        self.conv3 = EdgeConv(hidden_dim, hidden_dim)\n        \n        self.global_mlp = nn.Sequential(\n            nn.Linear(2, 12),\n            nn.ReLU(),\n            nn.BatchNorm1d(12))\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(12 + hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, 2))\n    \n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        \n        x = F.leaky_relu(self.conv1(x, edge_index))\n        x = F.leaky_relu(self.conv2(x, edge_index))\n        x = F.leaky_relu(self.conv3(x, edge_index))\n        \n        graph_feat = global_mean_pool(x, batch)\n        global_feat = self.global_mlp(torch.stack([data.m0, data.pt], dim=1))\n        \n        return self.classifier(torch.cat([graph_feat, global_feat], dim=1))\n\nclass NonLocalJetGNN(nn.Module):\n    def __init__(self, node_features=5, hidden_dim=64):\n        super().__init__()\n        self.conv1 = EdgeConv(node_features, hidden_dim)\n        self.conv2 = EdgeConv(hidden_dim, hidden_dim)\n        self.conv3 = EdgeConv(hidden_dim, hidden_dim)\n        \n        self.non_local = NonLocalBlock(hidden_dim)\n        \n        self.global_mlp = nn.Sequential(\n            nn.Linear(2, 12),\n            nn.ReLU(),\n            nn.BatchNorm1d(12))\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(12 + hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, 2))\n    \n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        \n        x = F.leaky_relu(self.conv1(x, edge_index))\n        x = F.leaky_relu(self.conv2(x, edge_index))\n        x = F.leaky_relu(self.conv3(x, edge_index))\n        \n        x = self.non_local(x, batch)  # Non-local aggregation\n        \n        graph_feat = global_mean_pool(x, batch)\n        global_feat = self.global_mlp(torch.stack([data.m0, data.pt], dim=1))\n        \n        return self.classifier(torch.cat([graph_feat, global_feat], dim=1))\n\n# ======================\n# 5. Training Utilities\n# ======================\nclass EarlyStopping:\n    def __init__(self, patience=5, delta=0, path='best_model.pt'):\n        self.patience = patience\n        self.delta = delta\n        self.path = path\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n\n    def __call__(self, val_loss, model):\n        if self.best_score is None:\n            self.best_score = val_loss\n            self.save_checkpoint(model)\n        elif val_loss > self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = val_loss\n            self.save_checkpoint(model)\n            self.counter = 0\n\n    def save_checkpoint(self, model):\n        torch.save(model.state_dict(), self.path)\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    pbar = tqdm(loader, leave=False, desc=\"Training\")\n    for data in pbar:\n        data = data.to(device)\n        optimizer.zero_grad()\n        out = model(data)\n        loss = criterion(out, data.y.squeeze())\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n    return total_loss / len(loader)\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    all_preds, all_targets = [], []\n    pbar = tqdm(loader, leave=False, desc=\"Validation\")\n    with torch.no_grad():\n        for data in pbar:\n            data = data.to(device)\n            out = model(data)\n            loss = criterion(out, data.y.squeeze())\n            total_loss += loss.item()\n            \n            probs = F.softmax(out, dim=1)\n            all_preds.append(probs[:, 1].cpu().numpy())\n            all_targets.append(data.y.squeeze().cpu().numpy())\n    \n    auc = roc_auc_score(np.concatenate(all_targets), np.concatenate(all_preds))\n    return total_loss / len(loader), auc\n\n# ======================\n# 6. Main Training Loop\n# ======================\ndef main():\n    # Config\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    threshold = 0.01\n    batch_size = 32\n    hidden_dim = 64\n    lr = 0.001\n    epochs = 100\n    num_jets = 30000  # Reduce if memory is limited\n    \n    # Load and preprocess data\n    print(\"Loading data...\")\n    graphs = load_data('/kaggle/working/filename', num_jets=num_jets, threshold=threshold)\n    \n    # Split data\n    train_graphs, val_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_graphs, batch_size=batch_size)\n    \n    # Initialize models\n    models = {\n        \"Baseline GNN\": JetGNN(hidden_dim=hidden_dim).to(device),\n        \"Non-Local GNN\": NonLocalJetGNN(hidden_dim=hidden_dim).to(device)\n    }\n    \n    results = {}\n    criterion = nn.CrossEntropyLoss()\n    \n    for name, model in models.items():\n        print(f\"\\n===== Training {name} =====\")\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n        early_stopping = EarlyStopping(patience=5, path=f'best_{name.lower().replace(\" \", \"_\")}.pt')\n        \n        best_auc = 0\n        for epoch in range(epochs):\n            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n            val_loss, val_auc = validate(model, val_loader, criterion, device)\n            \n            scheduler.step(val_loss)\n            if val_auc > best_auc:\n                best_auc = val_auc\n                torch.save(model.state_dict(), f'best_{name.lower().replace(\" \", \"_\")}_auc.pt')\n            \n            print(f\"Epoch {epoch+1:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f}\")\n            \n            early_stopping(val_loss, model)\n            if early_stopping.early_stop:\n                print(f\"Early stopping triggered for {name}!\")\n                break\n        \n        results[name] = best_auc\n    \n    print(\"\\n===== Final Results =====\")\n    for name, auc in results.items():\n        print(f\"{name}: ROC-AUC = {auc:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:34:50.677199Z","iopub.execute_input":"2025-04-01T09:34:50.677548Z","iopub.status.idle":"2025-04-01T09:39:57.441498Z","shell.execute_reply.started":"2025-04-01T09:34:50.677520Z","shell.execute_reply":"2025-04-01T09:39:57.440563Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Creating graphs:   0%|          | 0/30000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5390ca6e037b4a6f9c9e9d177b01db9a"}},"metadata":{}},{"name":"stdout","text":"\n===== Training Baseline GNN =====\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 001 | Train Loss: 0.6286 | Val Loss: 0.6140 | Val AUC: 0.7259\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 002 | Train Loss: 0.6196 | Val Loss: 0.6125 | Val AUC: 0.7283\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 003 | Train Loss: 0.6200 | Val Loss: 0.6122 | Val AUC: 0.7287\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 004 | Train Loss: 0.6187 | Val Loss: 0.6110 | Val AUC: 0.7288\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 005 | Train Loss: 0.6185 | Val Loss: 0.6110 | Val AUC: 0.7283\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 006 | Train Loss: 0.6192 | Val Loss: 0.6132 | Val AUC: 0.7275\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 007 | Train Loss: 0.6179 | Val Loss: 0.6115 | Val AUC: 0.7290\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 008 | Train Loss: 0.6173 | Val Loss: 0.6109 | Val AUC: 0.7291\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 009 | Train Loss: 0.6172 | Val Loss: 0.6110 | Val AUC: 0.7291\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 010 | Train Loss: 0.6169 | Val Loss: 0.6112 | Val AUC: 0.7292\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 011 | Train Loss: 0.6169 | Val Loss: 0.6105 | Val AUC: 0.7299\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 012 | Train Loss: 0.6165 | Val Loss: 0.6113 | Val AUC: 0.7283\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 013 | Train Loss: 0.6176 | Val Loss: 0.6107 | Val AUC: 0.7290\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 014 | Train Loss: 0.6166 | Val Loss: 0.6104 | Val AUC: 0.7296\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 015 | Train Loss: 0.6173 | Val Loss: 0.6105 | Val AUC: 0.7294\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 016 | Train Loss: 0.6166 | Val Loss: 0.6108 | Val AUC: 0.7290\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 017 | Train Loss: 0.6160 | Val Loss: 0.6104 | Val AUC: 0.7292\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 018 | Train Loss: 0.6159 | Val Loss: 0.6100 | Val AUC: 0.7294\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 019 | Train Loss: 0.6158 | Val Loss: 0.6102 | Val AUC: 0.7291\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 020 | Train Loss: 0.6167 | Val Loss: 0.6096 | Val AUC: 0.7296\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 021 | Train Loss: 0.6160 | Val Loss: 0.6114 | Val AUC: 0.7287\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 022 | Train Loss: 0.6163 | Val Loss: 0.6111 | Val AUC: 0.7293\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 023 | Train Loss: 0.6162 | Val Loss: 0.6105 | Val AUC: 0.7293\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 024 | Train Loss: 0.6160 | Val Loss: 0.6104 | Val AUC: 0.7295\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 025 | Train Loss: 0.6168 | Val Loss: 0.6098 | Val AUC: 0.7296\nEarly stopping triggered for Baseline GNN!\n\n===== Training Non-Local GNN =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 001 | Train Loss: 0.6269 | Val Loss: 0.6172 | Val AUC: 0.7282\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 002 | Train Loss: 0.6192 | Val Loss: 0.6167 | Val AUC: 0.7282\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 003 | Train Loss: 0.6209 | Val Loss: 0.6123 | Val AUC: 0.7282\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 004 | Train Loss: 0.6191 | Val Loss: 0.6145 | Val AUC: 0.7287\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 005 | Train Loss: 0.6190 | Val Loss: 0.6117 | Val AUC: 0.7290\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 006 | Train Loss: 0.6195 | Val Loss: 0.6103 | Val AUC: 0.7288\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 007 | Train Loss: 0.6182 | Val Loss: 0.6106 | Val AUC: 0.7288\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 008 | Train Loss: 0.6180 | Val Loss: 0.6129 | Val AUC: 0.7279\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 009 | Train Loss: 0.6183 | Val Loss: 0.6121 | Val AUC: 0.7281\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 010 | Train Loss: 0.6176 | Val Loss: 0.6109 | Val AUC: 0.7293\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 011 | Train Loss: 0.6174 | Val Loss: 0.6105 | Val AUC: 0.7293\nEarly stopping triggered for Non-Local GNN!\n\n===== Final Results =====\nBaseline GNN: ROC-AUC = 0.7299\nNon-Local GNN: ROC-AUC = 0.7293\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# import h5py\n# import numpy as np\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torch_geometric.data import Data, DataLoader\n# from torch_geometric.nn import MessagePassing, global_mean_pool\n# from sklearn.neighbors import radius_neighbors_graph\n# from sklearn.model_selection import train_test_split\n# from tqdm.auto import tqdm\n# from torch.optim.lr_scheduler import ReduceLROnPlateau\n# from sklearn.metrics import roc_auc_score\n# import gc\n\n# # ======================\n# # 1. Memory-Efficient Graph Creation\n# # ======================\n# def process_in_chunks(h5_path, chunk_size=30000, threshold=0.01):\n#     \"\"\"Process HDF5 file in chunks to save memory\"\"\"\n#     all_graphs = []\n#     with h5py.File(h5_path, 'r') as f:\n#         total_jets = f['X_jets'].shape[0]\n        \n#         for start_idx in tqdm(range(0, total_jets, chunk_size), \n#                           desc=\"Processing chunks\"):\n#             end_idx = min(start_idx + chunk_size, total_jets)\n            \n#             # Load chunk\n#             X_chunk = f['X_jets'][start_idx:end_idx]\n#             m0_chunk = f['m0'][start_idx:end_idx]\n#             pt_chunk = f['pt'][start_idx:end_idx]\n#             y_chunk = f['y'][start_idx:end_idx]\n            \n#             # Process chunk\n#             chunk_graphs = []\n#             for i in range(X_chunk.shape[0]):\n#                 data = multi_channel_image_to_graph(\n#                     X_chunk[i,0], X_chunk[i,1], X_chunk[i,2], threshold)\n#                 data.m0 = torch.tensor([m0_chunk[i]], dtype=torch.float)\n#                 data.pt = torch.tensor([pt_chunk[i]], dtype=torch.float)\n#                 data.y = torch.tensor([int(y_chunk[i])], dtype=torch.long)\n#                 chunk_graphs.append(data)\n            \n#             all_graphs.extend(chunk_graphs)\n            \n#             # Clean up memory\n#             del X_chunk, m0_chunk, pt_chunk, y_chunk, chunk_graphs\n#             gc.collect()\n    \n#     return all_graphs\n\n# # ======================\n# # 2. Early Stopping Class\n# # ======================\n# class EarlyStopping:\n#     def __init__(self, patience=5, delta=0, path='best_model.pt'):\n#         self.patience = patience\n#         self.delta = delta\n#         self.path = path\n#         self.counter = 0\n#         self.best_score = None\n#         self.early_stop = False\n\n#     def __call__(self, val_loss, model):\n#         if self.best_score is None:\n#             self.best_score = val_loss\n#             self.save_checkpoint(model)\n#         elif val_loss > self.best_score + self.delta:\n#             self.counter += 1\n#             if self.counter >= self.patience:\n#                 self.early_stop = True\n#         else:\n#             self.best_score = val_loss\n#             self.save_checkpoint(model)\n#             self.counter = 0\n\n#     def save_checkpoint(self, model):\n#         torch.save(model.state_dict(), self.path)\n\n# # ======================\n# # 3. Graph Construction \n# # ======================\n# def multi_channel_image_to_graph(ecal, hcal, track, threshold=0.01):\n#     \"\"\"Convert 3-channel jet image to graph\"\"\"\n#     nodes = []\n#     height, width = ecal.shape\n    \n#     for i in range(height):\n#         for j in range(width):\n#             total_energy = ecal[i,j] + hcal[i,j] + track[i,j]\n#             if total_energy > threshold:\n#                 nodes.append([\n#                     i/float(height),   # norm x\n#                     j/float(width),   # norm y\n#                     ecal[i,j],        # ECAL\n#                     hcal[i,j],        # HCAL\n#                     track[i,j]        # Track\n#                 ])\n    \n#     if len(nodes) == 0:  # Fallback\n#         combined = ecal + hcal + track\n#         max_idx = np.unravel_index(np.argmax(combined), combined.shape)\n#         nodes.append([\n#             max_idx[0]/float(height), max_idx[1]/float(width),\n#             ecal[max_idx], hcal[max_idx], track[max_idx]\n#         ])\n    \n#     nodes = np.array(nodes, dtype=np.float32)\n#     pos = nodes[:, :2]\n    \n#     if len(nodes) > 1:\n#         edges = radius_neighbors_graph(pos, radius=0.15, mode='connectivity')\n#         edge_index = torch.tensor(edges.nonzero(), dtype=torch.long)\n#     else:\n#         edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n    \n#     return Data(x=torch.tensor(nodes, dtype=torch.float),\n#                 edge_index=edge_index)\n\n# # ======================\n# # 4. GNN Model\n# # ======================\n# class EdgeConv(MessagePassing):\n#     def __init__(self, in_channels, out_channels):\n#         super().__init__(aggr='mean')\n#         self.mlp = nn.Sequential(\n#             nn.Linear(2*in_channels, out_channels),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(out_channels),\n#             nn.Linear(out_channels, out_channels)\n#         )\n    \n#     def forward(self, x, edge_index):\n#         return self.propagate(edge_index, x=x)\n    \n#     def message(self, x_i, x_j):\n#         return self.mlp(torch.cat([x_i, x_j-x_i], dim=1))\n\n# class JetGNN(nn.Module):\n#     def __init__(self, node_features=5, hidden_dim=64):\n#         super().__init__()\n#         self.conv1 = EdgeConv(node_features, hidden_dim)\n#         self.conv2 = EdgeConv(hidden_dim, hidden_dim)\n#         self.conv3 = EdgeConv(hidden_dim, hidden_dim)\n#         self.global_mlp = nn.Sequential(\n#             nn.Linear(2, 12),\n#             nn.ReLU(),\n#             nn.BatchNorm1d(12))\n#         self.classifier = nn.Sequential(\n#             nn.Linear(12 + hidden_dim, hidden_dim // 2),\n#             nn.ReLU(),\n#             nn.Linear(hidden_dim // 2, 2))\n    \n#     def forward(self, data):\n#         x, edge_index, batch = data.x, data.edge_index, data.batch\n#         x = F.leaky_relu(self.conv1(x, edge_index))\n#         x = F.leaky_relu(self.conv2(x, edge_index))\n#         x = F.leaky_relu(self.conv3(x, edge_index))\n#         graph_feat = global_mean_pool(x, batch)\n#         global_feat = self.global_mlp(torch.stack([data.m0, data.pt], dim=1))\n#         return self.classifier(torch.cat([graph_feat, global_feat], dim=1))\n\n# # ======================\n# # 5. Data Loading (First 30,000 jets only)\n# # ======================\n# def load_data(filename, num_jets=30000):\n#     with h5py.File(filename, 'r') as f:\n#         X_jets = f['X_jets'][:num_jets]  # Only load first 30,000 jets\n#         m0 = f['m0'][:num_jets]\n#         pt = f['pt'][:num_jets]\n#         y = f['y'][:num_jets]\n#     return X_jets, m0, pt, y\n\n# def create_graph_dataset(X_jets, m0, pt, y, threshold=0.01):\n#     graphs = []\n#     num_jets = X_jets.shape[0]\n    \n#     for i in tqdm(range(num_jets), desc=\"Creating graphs\"):\n#         ecal = X_jets[i, 0, :, :]  # ECAL channel\n#         hcal = X_jets[i, 1, :, :]  # HCAL channel\n#         track = X_jets[i, 2, :, :]  # Track channel\n        \n#         data = multi_channel_image_to_graph(ecal, hcal, track, threshold)\n#         data.m0 = torch.tensor([m0[i]], dtype=torch.float)\n#         data.pt = torch.tensor([pt[i]], dtype=torch.float)\n#         data.y = torch.tensor([int(y[i])], dtype=torch.long)\n#         graphs.append(data)\n    \n#     return graphs\n\n# # ======================\n# # 6. Training Loop with tqdm\n# # ======================\n# def train_epoch(model, loader, optimizer, criterion, device):\n#     model.train()\n#     total_loss, correct = 0, 0\n#     pbar = tqdm(loader, leave=False, desc=\"Training\")\n#     for data in pbar:\n#         data = data.to(device)\n#         optimizer.zero_grad()\n#         out = model(data)\n#         loss = criterion(out, data.y.squeeze())\n#         loss.backward()\n#         optimizer.step()\n        \n#         total_loss += loss.item()\n#         correct += (out.argmax(dim=1) == data.y.squeeze()).sum().item()\n#         pbar.set_postfix({\n#             'loss': f\"{loss.item():.4f}\",\n#             'acc': f\"{(out.argmax(dim=1) == data.y.squeeze()).float().mean().item():.4f}\"\n#         })\n    \n#     return total_loss/len(loader), correct/len(loader.dataset)\n\n# def validate(model, loader, criterion, device):\n#     model.eval()\n#     total_loss, correct = 0, 0\n#     all_preds = []\n#     all_targets = []\n#     pbar = tqdm(loader, leave=False, desc=\"Validation\")\n#     with torch.no_grad():\n#         for data in pbar:\n#             data = data.to(device)\n#             out = model(data)\n#             loss = criterion(out, data.y.squeeze())\n#             total_loss += loss.item()\n#             correct += (out.argmax(dim=1) == data.y.squeeze()).sum().item()\n            \n#             # Store predictions and targets for AUC calculation\n#             probs = F.softmax(out, dim=1)\n#             all_preds.append(probs[:, 1].cpu().numpy())  # Probability of class 1\n#             all_targets.append(data.y.squeeze().cpu().numpy())\n            \n#             pbar.set_postfix({\n#                 'val_loss': f\"{loss.item():.4f}\",\n#                 'val_acc': f\"{(out.argmax(dim=1) == data.y.squeeze()).float().mean().item():.4f}\"\n#             })\n    \n#     # Calculate AUC\n#     all_preds = np.concatenate(all_preds)\n#     all_targets = np.concatenate(all_targets)\n#     auc = roc_auc_score(all_targets, all_preds)\n    \n#     return total_loss/len(loader), correct/len(loader.dataset), auc\n\n# # ======================\n# # 7. Main Execution\n# # ======================\n# def main():\n#     # Config\n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#     threshold = 0.01\n#     patience = 5\n#     lr = 0.001\n#     batch_size = 32\n#     hidden_dim = 128\n#     chunk_size = 30000  # Process 30,000 jets at a time\n    \n#     # Process data in chunks\n#     print(\"Processing entire dataset in chunks...\")\n#     graphs = process_in_chunks('/kaggle/working/filename', chunk_size, threshold)\n    \n#     # Split data\n#     train_graphs, val_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n#     del graphs  # Free memory\n#     gc.collect()\n    \n#     # Create dataloaders\n#     train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n#     val_loader = DataLoader(val_graphs, batch_size=batch_size)\n    \n#     # Initialize model\n#     model = JetGNN(hidden_dim=hidden_dim).to(device)\n#     optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n#     scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n#     criterion = nn.CrossEntropyLoss()\n#     early_stopping = EarlyStopping(patience=patience, path='best_jetgnn.pt')\n    \n#     # Training loop\n#     best_auc = 0.0\n#     for epoch in range(100):\n#         # Training\n#         train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n        \n#         # Validation\n#         val_loss, val_acc, val_auc = validate(model, val_loader, criterion, device)\n        \n#         # Update scheduler\n#         scheduler.step(val_loss)\n        \n#         # Track best AUC\n#         if val_auc > best_auc:\n#             best_auc = val_auc\n#             torch.save(model.state_dict(), 'best_jetgnn_auc.pt')\n        \n#         # Print epoch stats\n#         print(f\"\\nEpoch {epoch+1:03d}\")\n#         print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n#         print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}\")\n#         print(f\"Best AUC: {best_auc:.4f}\")\n#         print(f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n        \n#         # Early stopping check\n#         early_stopping(val_loss, model)\n#         if early_stopping.early_stop:\n#             print(\"\\nEarly stopping triggered\")\n#             break\n    \n#     # Load best model (based on validation loss)\n#     model.load_state_dict(torch.load('best_jetgnn.pt'))\n#     print(\"\\nTraining complete. Best model saved to 'best_jetgnn.pt'\")\n#     print(f\"Best AUC during training: {best_auc:.4f}\")\n\n# if __name__ == \"__main__\":\n#     main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T09:29:26.760377Z","iopub.status.idle":"2025-04-01T09:29:26.760622Z","shell.execute_reply":"2025-04-01T09:29:26.760522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}